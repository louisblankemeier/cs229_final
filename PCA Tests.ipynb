{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_data = np.load('processed_data.npz')\n",
    "X = saved_data['X'][:170,:,:]\n",
    "X_sym = saved_data['X_sym'][:170,:,:]\n",
    "Y = saved_data['Y'][:170,:]\n",
    "Z = saved_data['Z'][:170,:]\n",
    "pids = saved_data['pids'][:170]\n",
    "\n",
    "M = X.shape[0]\n",
    "p = X.shape[1]; q = Y.shape[1]\n",
    "\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability of PCA Components (10-fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "comp = np.zeros((10,81,54756))\n",
    "c = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    x_train = X[train_index,:,0]\n",
    "    x_test = X[test_index,:,0]\n",
    "    \n",
    "    pca = PCA(n_components=81)\n",
    "    pca.fit_transform(x_train)\n",
    "    comp[c,:,:] = pca.components_\n",
    "    c += 1\n",
    "\n",
    "sim = np.zeros((45,81))\n",
    "c = 0\n",
    "for i in range(10):\n",
    "    for j in range(i+1,10):\n",
    "        sim[c,:] = np.diag(np.abs(comp[i,:,:] @ comp[j,:,:].T))\n",
    "        c += 1\n",
    "\n",
    "var = np.var(sim, axis=0)\n",
    "plt.figure()\n",
    "plt.plot(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability of PCA Components of Symmetric Data Matrix (10-fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = np.zeros((10,81,27495))\n",
    "c = 0\n",
    "for train_index, test_index in kf.split(X_sym):\n",
    "    x_train = X_sym[train_index,:,0]\n",
    "    x_test = X_sym[test_index,:,0]\n",
    "    \n",
    "    pca = PCA(n_components=81)\n",
    "    pca.fit_transform(x_train)\n",
    "    comp[c,:,:] = pca.components_\n",
    "    c += 1\n",
    "\n",
    "sim = np.zeros((45,81))\n",
    "c = 0\n",
    "for i in range(10):\n",
    "    for j in range(i+1,10):\n",
    "        sim[c,:] = np.diag(np.abs(comp[i,:,:] @ comp[j,:,:].T))\n",
    "        c += 1\n",
    "\n",
    "var = np.var(sim, axis=0)\n",
    "plt.figure()\n",
    "plt.plot(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean/Variance of Normalized Error from PCA of X Over 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err = np.zeros((10,80))\n",
    "test_err = np.zeros((10,80))\n",
    "\n",
    "s = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    x_train = X[train_index,:,0]\n",
    "    x_test = X[test_index,:,0]\n",
    "    train_norms = np.linalg.norm(x_train, axis=1)\n",
    "    test_norms = np.linalg.norm(x_test, axis=1)\n",
    "    pca = PCA(n_components=81)\n",
    "    pca.fit_transform(x_train)\n",
    "    components = pca.components_\n",
    "    for d in range(1,81):\n",
    "        comp = components[:d,:]\n",
    "        xh_train = x_train @ comp.T @ comp\n",
    "        xh_test = x_test @ comp.T @ comp\n",
    "        train_err[s,d-1] = np.mean(np.linalg.norm(xh_train - x_train, axis=1) / train_norms) # error normalized by magnitude of data\n",
    "        test_err[s,d-1] = np.mean(np.linalg.norm(xh_test - x_test, axis=1) / test_norms) # error normalized by magnitude of data\n",
    "    s += 1\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.mean(train_err,axis=0)); plt.plot(np.mean(test_err,axis=0))\n",
    "plt.figure()\n",
    "plt.plot(np.var(train_err,axis=0)); plt.plot(np.var(test_err,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean/Variance of Normalized Error from PCA of Y Over 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_err = np.zeros((10,40))\n",
    "y_test_err = np.zeros((10,40))\n",
    "y_explained_var = np.zeros((10,41))\n",
    "\n",
    "s = 0\n",
    "for train_index, test_index in kf.split(Y):\n",
    "    y_train = Y[train_index,:] + 1\n",
    "    y_test = Y[test_index,:] + 1\n",
    "    train_norms = np.linalg.norm(y_train, axis=1)\n",
    "    test_norms = np.linalg.norm(y_test, axis=1)\n",
    "    pca = PCA(n_components=41,whiten=False)\n",
    "    pca.fit_transform(y_train)\n",
    "    components = pca.components_\n",
    "#     y_explained_var[s,:] = pca.explained_variance_ratio_\n",
    "    for d in range(1,41):\n",
    "        comp = components[:d,:]\n",
    "        yh_train = y_train @ comp.T @ comp\n",
    "        yh_test = y_test @ comp.T @ comp\n",
    "        y_explained_var[s,d] = np.sum(pca.explained_variance_ratio_[:d])\n",
    "        y_train_err[s,d-1] = np.mean(np.linalg.norm(yh_train - y_train, axis=1) / train_norms)\n",
    "        y_test_err[s,d-1] = np.mean(np.linalg.norm(yh_test - y_test, axis=1) / test_norms)\n",
    "    s += 1\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.mean(y_explained_var,axis=0)); plt.grid()\n",
    "plt.figure()\n",
    "plt.plot(np.mean(y_train_err,axis=0)); \n",
    "plt.plot(np.mean(y_test_err,axis=0))\n",
    "plt.figure()\n",
    "plt.plot(np.var(y_train_err,axis=0)); \n",
    "plt.plot(np.var(y_test_err,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean/Variance of Normalized Error from PCA of Z Over 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train_err = np.zeros((10,29))\n",
    "z_test_err = np.zeros((10,29))\n",
    "z_explained_var = np.zeros((10,30))\n",
    "\n",
    "s = 0\n",
    "for train_index, test_index in kf.split(Z):\n",
    "    z_train = Z[train_index,:] + 1\n",
    "    z_test = Z[test_index,:] + 1\n",
    "    train_norms = np.linalg.norm(z_train, axis=1)\n",
    "    test_norms = np.linalg.norm(z_test, axis=1)\n",
    "    pca = PCA(n_components=30,whiten=False)\n",
    "    pca.fit_transform(z_train)\n",
    "    components = pca.components_\n",
    "#     z_explained_var[s,:] = pca.explained_variance_ratio_\n",
    "    for d in range(1,30):\n",
    "        comp = components[:d,:]\n",
    "        zh_train = z_train @ comp.T @ comp\n",
    "        zh_test = z_test @ comp.T @ comp\n",
    "        z_explained_var[s,d] = np.sum(pca.explained_variance_ratio_[:d])\n",
    "        z_train_err[s,d-1] = np.mean(np.linalg.norm(zh_train - z_train, axis=1) / train_norms)\n",
    "        z_test_err[s,d-1] = np.mean(np.linalg.norm(zh_test - z_test, axis=1) / test_norms)\n",
    "    s += 1\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.mean(z_explained_var,axis=0)); plt.grid()\n",
    "plt.figure()\n",
    "plt.plot(np.mean(z_train_err,axis=0)); \n",
    "plt.plot(np.mean(z_test_err,axis=0))\n",
    "plt.figure()\n",
    "plt.plot(np.var(z_train_err,axis=0)); \n",
    "plt.plot(np.var(z_test_err,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Q1 Using 81-dimensions of X (10-fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err = np.zeros((5,))\n",
    "test_err = np.zeros((5,))\n",
    "\n",
    "s = 0\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    x_train = X[train_index,:,0]\n",
    "    x_test = X[test_index,:,0]\n",
    "#     pca = PCA(n_components=81)\n",
    "#     xh_train = pca.fit_transform(x_train)\n",
    "#     xh_test = pca.transform(x_test)\n",
    "    y_train = Y[train_index,0]; y_test = Y[test_index,0]\n",
    "    clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(x_train, y_train)\n",
    "    yh_train = clf.predict(x_train)\n",
    "    yh_test = clf.predict(x_test)\n",
    "\n",
    "    train_err[s] = 1 - sum(y_train == yh_train) / len(y_train)\n",
    "    test_err[s] = 1 - sum(y_test == yh_test) / len(y_test)\n",
    "    \n",
    "    s += 1\n",
    "\n",
    "print(\"Mean Training Error: %.3f\" % np.mean(train_err))\n",
    "print(\"Mean Test Error: %.3f\" % np.mean(test_err))\n",
    "print(\"Std Training Error: %.3f\" % np.std(train_err))\n",
    "print(\"Std Test Error: %.3f\" % np.std(test_err))\n",
    "plt.figure()\n",
    "plt.hist(train_err);\n",
    "plt.figure()\n",
    "plt.hist(test_err);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting All Questions Using 81-dimensions of X (10-fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err = np.zeros((5,41))\n",
    "test_err = np.zeros((5,41))\n",
    "\n",
    "s = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    x_train = X[train_index,:,0]\n",
    "    x_test = X[test_index,:,0]\n",
    "    pca = PCA(n_components=81)\n",
    "    xh_train = pca.fit_transform(x_train)\n",
    "    xh_test = pca.transform(x_test)\n",
    "    for q in range(41):\n",
    "        y_train = Y[train_index,q]; y_test = Y[test_index,q]\n",
    "        clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(xh_train, y_train)\n",
    "        yh_train = clf.predict(xh_train)\n",
    "        yh_test = clf.predict(xh_test)\n",
    "\n",
    "        train_err[s,q] = 1 - sum(y_train == yh_train) / 153\n",
    "        test_err[s,q] = 1 - sum(y_test == yh_test) / 17\n",
    "    \n",
    "    s += 1\n",
    "\n",
    "print(\"Mean Training Error Across All Questions: %.3f\" % np.mean(train_err))\n",
    "print(\"Mean Test Error Across All Questions: %.3f\" % np.mean(test_err))\n",
    "plt.figure()\n",
    "plt.hist(np.mean(train_err,axis=0));\n",
    "plt.figure()\n",
    "plt.hist(np.mean(test_err,axis=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Questionnaire Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(Y.flatten())\n",
    "plt.figure()\n",
    "plt.hist(Z.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
